# Deep Learning

## Deep Learning History

Neural networks are the cornerstone of deep learning.

Neural networks first rose to fame in the late 1980s.

They fell out of favour when SVM, boosting and random forests came along.

Neural networks resurfaced after 2010 under the new name 'deep learning'.

## ImageNet Dataset

Massive collection of over 14,000,000 labelled images.

Designed to overcome shortcomings with existing benchmarks, e.g. small number of categories.

Collection of nouns - each noun maps to a number of real-world images.

## ImageNet Competition

Computer vision competition runs since 2010.

Classification of ImageNet images - 1.2 million training and 150,000 test images belonging to 1,000 classes.

Early competitions dominated by SVMs.

In 2012, AlexNet achieved error rate of about 15%. By 2017 most of teams scored > 95% accuracy (> human accuracy on this task).

## Feature Extraction

In order to effectively classify or regress, raw inputs must be extracted into high level features.

When using "ordinary ML" the first step is feature extraction, e.g. PCA.

Deep learning is an example of representation learning - raw data is fed in and identifies representations needed for accurate predictions.

Feature extraction is done by the algorithm, not relying on human expertise.

## Deep Learning

Neural networks with lots of layers
- Layers act as feature extractors
- Features are passed onto the next layer
- Raw input data is repeatedly processed before it reaches the output layer
- Result is a black box - part of the drive behind explainable AI
- ANNs are prone to overfitting, so are deep learning models

## Multilayer Neural Networks

A neural network takes an input of $p$ variables

$X = (X_1, X_2, \dots, X_p)$ and builds a nonlinear function $f(X)$ to predict $Y$.

$$f(X) = \beta_0 + \sum^k_{k=1} \beta_k A_k$$

$$A_k = g(W_{K_0} + \sum^p_{j=1} W_{kj} X_j)$$

Typically we have more than one hidden layer.

It is easier to find a good solution to a problem with multiple layers of modest size.

![](https://cdn-images-1.medium.com/max/800/0*eaw1POHESc--l5yR.png)

## Convolutional Neural Networks

A special family of convolutional neural networks evolved to tackle image classification.

Pioneered by Yann LeCunn in the 1980s.

Lower layers transform or convolve the inputs and pool features.

Higher levels act as an ordinary neural network using the outputs of the lower layers as inputs.

### Convolutional And Pooling Maps

![](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-024-51258-6/MediaObjects/41598_2024_51258_Fig1_HTML.png)

### Convolutional layers

Units are organized into feature maps 

Identify local features (e.g. edges) - features that can occur anywhere in the image

Each convolutional layer is made up of convolutional filters.

$$\text{Original Image} = 
\begin{bmatrix}
    a & b & c \\
    d & e & f \\
    g & h & i \\
    j & k & l
\end{bmatrix} 

\text{Convolution Filter} =
\begin{bmatrix}
    \alpha & \beta \\
    \gamma & \delta
\end{bmatrix}
$$

$$
\text{Convolved Image} = 
\begin{bmatrix}
    a \alpha + b \beta + d \gamma + e \delta \quad
    b \alpha + c \beta + e \gamma + f \delta \\

    d \alpha + e \beta + g \gamma + h \delta \quad
    e \alpha + f \beta + h \gamma + i \delta \\

    g \alpha + h \beta + j \gamma + k \delta \quad
    h \alpha + i \beta + k \gamma + l \delta \\
\end{bmatrix}
$$

If the $n × n$ submatrix of the original matrix is similar to the convolution filter, then it will have a large value in the convolved image.

This means that the convolved image highlights regions of the original image that resemble the convolution filter.

In general convolution filters are small ($\gamma_1$ × $\gamma_2$ arrays).

In image processing, standard practice is to draw from filters which have been predefined.

With CNNs the filters are learned for the specific classification task.
- As the input is colour, there are three channels represented by a three-dimensional feature map.
- If we use $K$ different convolution filters at the first hidden layer, we get $K$ two dimensional output feature maps.
- We typically apply the ReLU activation function to the convolved image.

### Pooling layers

Summarise the features identified in the convolutional layers without accounting for the location

This layer provides a way to condense a large image into a smaller summary image.

The max pooling operation summarises each non-overlapping 2 × 2 block of pixels in an image using the maximum value in the block.

Provides some location invariance.

$$
\text{Max pool} 
\begin{bmatrix}
1 & 2 & 5 & 3 \\
3 & 0 & 1 & 2 \\
2 & 1 & 3 & 4 \\
1 & 1 & 2 & 0
\end{bmatrix}
\rightarrow
\begin{bmatrix}
3 & 5 \\
2 & 4
\end{bmatrix}
$$

The average pooling operation summarises each non-overlapping 2 × 2 block of pixels in an image using the arithmetic mean of the block.

$$
\text{Average pool} 
\begin{bmatrix}
1 & 2 & 5 & 3 \\
3 & 0 & 1 & 2 \\
2 & 1 & 3 & 4 \\
1 & 1 & 2 & 0
\end{bmatrix}
\rightarrow
\begin{bmatrix}
1.5 & 2.75 \\
1.25 & 2.25
\end{bmatrix}
$$

The number of convolution filters in a convolution layer can be equated to the number of units at a particular hidden layer of a fully connected neural network.

## CNN Architecture

The number of convolution filters in a convolution layer can be equated to the number of units at a particular hidden layer of a fully connected neural network.

![](https://vitalflux.com/wp-content/uploads/2021/11/VGG16-CNN-Architecture.png)

Each subsequent convolve layer is similar to the first.

Since the channel feature maps are reduced in size after each pool layer, the number of filters in the next convolve layer is increased.

Occasionally several convolve layers are repeated before a pool layer.

Once each channel feature map has been reduced to the size of a few pixels in each dimension, we say they have been
flattened.

There are many tuning parameters that need to be selected during the construction of the network.

## Recurrent Neural Networks

RNNs allow previous outputs to be used as inputs so that history can be incorporated.

Useful in natural language processing and sentiment analysis.

![](https://miro.medium.com/v2/resize:fit:751/1*dznTsiaHCvRc70fxWWEcgw.png)

For RNNs we have an input sequence:

$$X = (X_1, X_2, X_3, \dots, X_L)$$

The output Y can also be a sequence but is often scalar.

The network consists of a sequence of activation functions, each of which feeds into the output layer.

The last of the output layers is the most relevant.

## Network Tuning

- The number of hidden layers
- Regularisation tuning parameters
- Details of stochastic gradient descent

## Generative Adversarial Networks

Given a dataset, generative models are unsupervised techniques for producing new examples that could belong to the dataset.

GANs enable supervised learning.

- One to generate new examples
- One to classify examples as either real or fake

Deep Convolutional Generative Adversarial Networks proposed in 2015 and are the basis for most modern GANs.

## Explainable Deep Learning

Deep learning models are generally considered black boxes - it's not possible to see their inner workings.

Many application areas cannot have this lack of transparency.

Explainable AI is intended to address this by exposing how the models have generated a result.

ImageNet challenges have considered this - with a localization sub-challenge.

## Difficulties With Deep Learning

Lots of data is required - this is becoming less of a challenge but there are still difficulties (e.g. getting labelled data).

Training deep learning networks requires substantial computational power because of massive number of networks
weights to calibrate - GPUs often used.

Deep neural networks are generally for supervised learning - if we want to achieve general AI we will need unsupervised
learning models.

"Deep" refers to the network architecture rather than understanding
