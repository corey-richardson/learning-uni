# COMP1001 Computer Systems
# 2023-11-06 Vectorization I, Writing Assembly in C/C++

---

- Different ways of writing assembly code
- Using intrinsic functions in C/C++
- Writing C/C++ programs using Intel SSE intrinsics
- Writing C/C++ programs using Intel AVX intrinsics

---

- An entire function in assembly
- Inline assembly c/c++
- Intrisic functions c/c++
    - Easier and safer
    - All compilers support intrinsic functions
    - Equivalent to an assembly function
    - Mixes the advantages of C/C++ and Assembly
        - C/C++: Development time, portability, maintainability
        - ASM: Execution time

C and C++ are the most easily combined langages with Assembly.

90% of execution time tends to be due to 10% of the code; performance bottlenecks.

**Main advantages**
- Classes, if conditions, loops and functions are very easy to implement
- Portability to almost all x86 architectures
- Compatibility with different compilers

**Main disadvantages**
- Not all assembly instructions have intrinsic function equivalents
- Unskilled use of intrinsic functions can make the code less efficient
than simple C++ code

---

## Computer Systems Hardware Evolution

- Scalar Processors
- Pipelined Processors
- Superscalar and VLIW Processors
- Out of order Processors
- Processors support *vectorization*
- Hyperthreading
- Multicore Processors
- Manycore Processors
- Heterogeneous systems

## Vectorization

Each CPU family supports a different instruction set.

*Intel MMX technology* (old â€“ limited usage nowadays)
- 8 mmx registers of 64 bit
- extension of the floating point registers
- can be handled as 8 8-bit, 4 16-bit, 2 32-bit and 1 64-bit, operations

*Intel SSE technology*
- 8/16 xmm registers of 128 bit (32-bit architectures support 8 registers only)
- Can be handled from 16 8-bit to 2 64-bit operations

*Intel AVX technology*
- 8/16 ymm registers of 256 bit (32-bit architectures support 8 registers only)
- Can be handled from 32 8-bit to 4 64-bit operations

*Intel AVX-512 technology*
- 32 ZMM 512-bit registers

![](/COMP1001/res/2023-11-06_01.png)
> How many operations in parallel <br>
> <sub>1 byte is 8 bits</sub>

[Intel Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)

`__m128 _mm_loadu_ps (float * mem_addr)` 
- Loads four floating point values (packed) from memory to `var1`
- e.g., `var1 = _mm_loadu_ps ( &A[3][4] );`

`void _mm_storeu_ps(float * mem_addr, __m128 a)`
- Stores four floating point values, from variable a to memory
- e.g., `_mm_storeu_ps (&array[4], num3);`

`__m128 _mm_mul_ps(__m128 a, __m128 b)`
- Multiplies the four single precision floating point values of `a` and `b`

`__m128 _mm_mul_ss(__m128 a, __m128 b)`
- Multiplies the lower SP FP values of `a` and `b`; the upper 3 SP FP values are passed through from `a`.

![](/COMP1001/res/2023-11-06_02.png)

`__m128 _mm_unpackhi_ps (__m128 a, __m128 b) `
- Selects and interleaves the upper two SP FP values from `a` and `b`.

`__m128 _mm_unpacklo_ps (__m128 a, __m128 b) `
- Selects and interleaves the lower two SP FP values from `a` and `b`.

![](/COMP1001/res/2023-11-06_03.png)

### Vectorization Example 1

```cpp
for (j = 0; j < M; j++) 
{
    V1[j] = V2[j] + 2.1234;
}
```

The compiler will automatically vectorize simple loop kernels; auto-vectorization.

*Without vectorization*
- Load `V2[0]`
- `V2[0]+2.12`
- Store the result into `V1[0]`
- Repeat for `1`-`3`.

*With vectorization*
- Load `V2[0:3]` (load 4 values together)
- `V2[0:3] + 2.12` (apply 4 additions together)
- Store the result into `V1[0:3]` (store 4 values together)

### Vectorization Example 2

```cpp
for (j = 0; j < M; j++) 
{
    V1[j] = V2[j] + 2.1234;
}
```

- 4 elements are processed together using vector instructions
- Performance is improved by x4

```cpp
__m128 num1, num2, num3;
// Save 4 copies of constant operand
num1 = _mm_set_ps (2.12, 2.12, 2.12, 2.12);

for (int i = 0; i < M; i += 4) 
{
    num2 = _mm_load_ps (&V2[i]);
    num3 = _mm_add_ps (num1, num2);
    _mm_store_ps( &V1[i], num3);
}
```

![](/COMP1001/res/2023-11-06_04.png)

What if `M == 10`? Not a multiple of 4.

```cpp
__m128 num1, num2, num3;
num1 = _mm_set_ps (2.12, 2.12, 2.12, 2.12);

for (int i = 0; i < 8; i += 4) 
{
    num2 = _mm_load_ps (&V2[i]);
    num3 = _mm_add_ps (num1, num2);
    _mm_store_ps( &V1[i], num3);
}

for (j = 8; j < 10; j++) 
{
    V1[j] = V2[j] + 2.1234;
}
```

## Using Intrinsic Functions in C/C++

All modern processors support vectorization; processors have extra hardware components (*wide registers* - up to 512-bits - and *wide processing units*) to allow vector processing.

```cpp
unsigned short int ConstAdd_SSE() {

	__m128 num1, num2, num3;
	int i;

	num1 = _mm_set_ps(2.1234f, 2.1234f, 2.1234f, 2.1234f); //set num1 values

	for (i = 0; i < M; i += 4) { //IMPORTANT: M MUST BE A MULTIPLE OF 4, OTHERWISE IT DOES NOT WORK
		num2 = _mm_loadu_ps(&V2[i]); //load 4 elements of V2[]
		num3 = _mm_add_ps(num1, num2); //num3 = num1 + num2
		_mm_storeu_ps(&V1[i], num3); //store num3 to Y[i]. num3 has 4 FP values which they are stored into Y[i], Y[i+1], Y[i+2], Y[i+3], respectively
	}


	return 2;
}
```

`__m128 num1, num2, num3;` initialises three 128-bit wide variables.

`num1 = _mm_set_ps(2.1234f, 2.1234f, 2.1234f, 2.1234f);` stores the four floating point values in the wide variable.

`num2 = _mm_loadu_ps(&V2[i]);` loads 4 elements pf `V2` -> `V2[i]`, `V2[i+1]`, `V2[i+2]`, `V2[i+3]`



```cpp
for (int i = 0; i < M3; i++) {
    y = 0.0f;
    y_vec = _mm_set_ps(y, y, y, y);

    for (int j = 0; j < M3; j++) {
        /*
        y = y + A1[i][j  ] * X[j  ]
        y = y + A1[i][j+1] * X[j+1]
        y = y + A1[i][j+2] * X[j+2]
        y = y + A1[i][j+3] * X[j+3]
        */
        a1 = _mm_loadu_ps(&A1[i][j]);
        x  = _mm_loadu_ps(&X[j]);
        a1 = _mm_mul_ps(a1, x);
        y_vec = _mm_add_ps(y_vec, a1);
    }
}
```

[CS3330 Fall 2018 SIMD Reference](https://www.cs.virginia.edu/~cr4bd/3330/F2018/simdref.html)

---

## Video - [Parallel C++: Vectorization](https://youtu.be/VU8jSh5v5C8?si=LFI4_M_rX_c_NfqT)

- Vectorization
- Vector Instructions
- SIMD: Single Instruction, Multiple Data
- Auto-vectorization by compiler

## Video - [Parallel C++: SIMD Intrinsics](https://youtu.be/PuOGJ527k5E?si=GTppU0Rbmhejou-5)

