# COMP1001 Computer Systems
# 2023-10-19 Modern CPU Hardware Architectures

---

- Superscalar Processors
- Superpipelining Processors
- In Order and Out Of Order Processors
- RISC, CISC Processors
- Moore's Law and Hardware Architecture Laws

---

By adding pipeline stages the number of clock cycles is reduced but control and data hazards increase and become costlier.

`stall`

---

## Superscalar Processors

A superscalar processor can execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to different execution units on the processor.

Duplicates the pipeline to accommodate Instruction Level Parallelism (ILP).

It therefore achieves more throughput (the number of instructions that can be executed in a unit of time) that would otherwise be impossible at a given clock rate.

Superscalar machines issue a variable number of instructions each clock cycle, up to some maximum.
- instructions must be independent - no data or control dependencies

![](/COMP1001/res/2023-10-19_01.png)

> If the instructions are *interdependent*, then superscalar architecture does **not** improve performance. 


- Extra hardware to simultaneously fetch multiple instructions is needed
- Hardware logic to determine data dependencies is needed, involving the registers' values
- Extra hardware (functional units) to execute multiple instructions in parallel
- Extra hardware (functional units) to issue multiple instructions in parallel

> Duplicating the hardware in just one pipeline stage doesn't help (i.e. having two ALU but only one instruction can be loaded at a time from memory); it just moves the bottleneck elsewhere. <br>
> *ALL* phases of the pipeline need to be duplicated.

What if two successive instructions canâ€™t be executed in parallel?
> Superscalar operation is double impacted by a stall

Depends on Instruction Level Parallelism <br>
Depends on Compiler Base Optimisation

Limited by Data Dependencies <br>
Limited by Control Dependencies

## Superscalar vs Superpipelining

- Superscalar: duplication of phases
- Superpipelining: lots of stages

Modern systems use both.

![](/COMP1001/res/2023-10-19_02.png)

## Out Of Order

A superscalar processor can fetch, decode, execute more than one instructions in parallel but can execute only independent instructions in parallel whereas adjacent instructions are usually dependent so the utilisation of the second pipeline is low.

Execute independent instructions in a different, more efficient order.

A specific HW mechanism examines a *sliding window* of consecutive instructions: *instruction window*.

*Ready* instructions get picked up from the window and executed out of order.
> Ready: Instructions where the operands are available.

Instructions enter (dispatched) and leave (committed) the instruction window in program order, and an instruction can only leave the window when it is the oldest instruction in the window and it has been completed.

![](/COMP1001/res/2023-10-19_03.png)

Move the dependent instructions out of the way of independent
ones.

Rest areas for dependent instructions: *Reservation station*

Instruction window: It is a memory that holds the instructions that have been fetched and decoded and are waiting to be executed.

![](/COMP1001/res/2023-10-19_04.png)

- `+` Exploit ILP
- `+` Hide Latencies (e.g. L1 Data Cache Miss, Division) 
- `-` More Expensive
- `-` Larger Chip Area
- `-` Higher Power Consumption

Compilers can do this work instead (kind of).

Compilers lack runtime information.
- Conditional Branch Direction
- Data Values
- Cache Miss / Hit

## OoO Pipeline

**Dispatch**
- new instructions are added to the instruction window - reservation stations (RS)

**Reservation stations (RS)**
- Instructions wait for their inputs
- Instructions wait for their functional units
- If instruction operands are ready they are sent to the FU
- Otherwise, check on bypass network and wait for operands

**Functional units (FU)**
- ALUs, AGUs, FPUs

**Bypass network**
- Broadcast computed values back to reservation stations

**ReOrder buffer (ROB)**
- It allows instructions to be committed in-order
- De-speculates execution, mostly by Committing instructions in-order
- flushes the speculative instructions when a misprediction is discovered 

**Commit**
- All execution within the instruction window is speculative (i.e., side-effects are not applied outside the CPU) until it is committed
- Instructions can write to memory only once it is certain they should have been executed
- Instructions must not affect machine state while they are speculative
- Instructions enter and leave the instruction window in program order, and an instruction can only leave the window when it is the oldest instruction in the window and it has been completed

**Store Buffer**
- Stores are not executed Out of Order (OoO)
    - Stores are never performed speculatively
    - There is no transparent way to undo them
- Stores are also never re-ordered among themselves
    - The Store Buffer dispatches a store only when
        - The store has both its address and its
data ready and
        - There are no older stores awaiting dispatch

## OoO Summary

Advantages
- Help exploit Instruction Level Parallelism (ILP)
- Help hide latencies (e.g., cache miss, divide)
- Superior/complementary to instuction Scheduler in the compiler
    - Dynamic instruction window

Complex micro-architecture - hardware
- Complex instruction logic
- Requires reordering mechanism (retire/commit)
- Misprediction/speculation recovery

Speculative Execution
- Advantage: larger scheduling window --> reveals more ILP
- Issues:
    - Complex logic needed to recover from mis-prediction
    - Runtime cost incurred when recovering from a mis-prediction

## Comparison of different processors

![](https://www.lighterra.com/papers/modernmicroprocessors/brainiacs22.svg)

[Recommended Reading](https://www.lighterra.com/papers/modernmicroprocessors/)

**Brainiac Designs**
- Extra HW in order to achieve more Instruction Level Parallelism (ILP)
out of the code
- Millions of extra transistors
- More design effort
- Consume more power

**Speed-Demons**
- Run at higher clock speeds because they are simpler
- Simple HW design
- Less Chip area
- Less power consumption

## Instruction Set Architecture (ISA)

ISA is analogous to human language

Software to hardware

Complex Instruction Set Computer (CISC) <br>
Reduced Instruction Set Computer (RISC)

Complex instruction set computer (CISC): complex instructions can execute several low-level operations (such as a load from memory, an arithmetic operation, and a memory store)
- CISC puts emphasis on HW
- CISC was developed to make compiler development simpler
- CISC is typically used for general purpose computers

Reduced instruction set computer (RISC): simple and 1 cycle instructions
- RISC puts emphasis on SW
- RISC was developed to make HW simpler
- RISC is typically used for smart phones, tablets and other embedded devices

## Hardware Architecture Trends

![](https://upload.wikimedia.org/wikipedia/commons/0/00/Moore%27s_Law_Transistor_Count_1970-2020.png)

![](/COMP1001/res/2023-10-19_05.png)

Frequency ceased increasing in 2006: <br> 

$$\text{Power Consumption} \propto \text{Frequency}^2$$ 

Therefore, increasing frequency further would require expensive cooling systems.

The solution to this was to introduced multiple logical cores per chip; parallelism.

> FLOPS: Floating Point Operations Per Second

[Why We're Reaching the Theoretical Limit of Computer Power](https://www.youtube.com/watch?v=Qlv5pB6u534)
> Quantum Tunnelling could cause electrons to flow in a transistor even during 0-state. Transistors are 2nm wide; ~10 Silicon atoms. 

Silicon, Phosphorus | Silicon, Boron | Silicon, Phosphorus

`|` indicates depletion zones. Pass `+` charge through `-` depletion zones to neutalise them, allowing flow of electrons / charge (1-state).

