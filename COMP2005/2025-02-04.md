# Software Testing

1. Testing within the software development life cycle
2. Types of testing and their advantages and disadvantages
3. Test design and coverage

## Testing Overview

Software Development is a complex sequence of activities; errors may propagate throughout.

Testing is an integral part of the development process. It can optimise cost and resources in the long run by reducing bugs, and improving the quality of a software release.

## Principles of Software Testing

Software testing has 7 guideline principles.

1. Testing shows the presence of defects, not the absence.
    - Design test case > Find SW defects > Confidence that it is working
    - Does not confirm that SW is *completely* correct and *completely* error free

2. Exhaustive testing is not possible.
    - Impossible/impractical to test ALL possible input cases, data and scenario combinations
    - Therefore, test sampless are based on risk and priorities.

3. Early testing saves time and money.
    - Prepare tests early and regulary; for each phase of the SDLC.

4. Defects often cluster together.
    - Pareto Principle (80:20); 80% of defects are often due to 20% of the code.
    - Finding 1 defect in a module indicates a strong chance to discover other defects.
    - Certain software components are more prone to errors. Identify: Complexity, Dependencies, Frequent Changes
    - Concentrate the testing on these risk areas.

5. Testing is context-dependent.
    - Application Context: requirements vary, methods, purposes, risks
    - Domains: banking, insurance, travel, healthcare, aviation

6. Beware of the Pesticide Paradox
    - Keep reviewing the tests - add to or modify the test scenarios.
    - Using the same test cases continuously suggests that software is working, so new defects are missed.
    - Continue with manual testing.
    - Test the tests; intentionally break the code to check errors are picked up.

7. Error Absence Fallacy
    - Software not meeting user requirements > defects fixed > error free > irrelevant
    - Usefulness, Usability, Learnability
    - Early prototypes

Even after all testing, you're never certain software is bug free.

However, appropriate testing REDUCES the probability of undiscovered defects.

## Software Testing Life Cycle (STLC)

A sequence of different activities; testing is not just a single activity.

Testing contains both verification and validation activities.

1. Requirements Analysis
    - Test team studies requirements; identify testable items.
    - Contact stakeholders for better understanding of requirements and priorities.
    - Functional and non-functional requirements.

2. Test Planning
    - Outline strategy, required resources, environment, limitations and schedule of testing activities.
    - Common test types: Unit Test, Integration Test, System Test

3. Test Case Development
    - Creation and revision of test cases and test data, once the test plan is ready.
    - Designed test cases are peer reviewed.

4. Environment Setup
    - Setup software and hardware to execute the designed test cases.

5. Test Execution
    - Execute the code and compare expected and actual results.
    - Test script execution, test script maintenance, and bug reporting.

6. Test Cycle Closure
    - Completion of test executions; team members meet.
    - Discuss and analyse the test artifacts.
    - Identify future strategies.
    - Lessons learned.
    - Test closure report published indication test summary and results.

## V-Model (SDLC + STLC)

> The V-model is a type of SDLC model where the process executes sequentially in a V-shape. It is also known as the Verification and Validation model. It is based on the association of a testing phase for each corresponding development stage. The development of each step is directly associated with the testing phase. The next phase starts only after completion of the previous phase i.e., for each development activity, there is a testing activity corresponding to it.

![](https://media.geeksforgeeks.org/wp-content/uploads/20231030123258/software-Testing-Tutorial-SDLC-V-model.webp)

![](https://media.licdn.com/dms/image/v2/C5612AQFWqUlHNgaKoA/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1520237120506?e=2147483647&v=beta&t=xztnqvCLQVJMDbIwSP56_IalE-580tTaczs5dGzUBTE)

Extension of the Waterfall model. Based on the association of testing phases for each corresponding development phase. 

**Concept of Operations (ConOps)**
- Depends on the project size and the client
- User-oriented document describing characteristics, goals and objectives of the proposed system, from the viewpoint of the individual who will use that system.
- Describes *what* the system will do - not how it will do it - and *why*.
- Describes any critical top-level performance requirements, either stated qualitatively or quantitatively.

**Requirements and Architecture**
- Gather requirements are translated into specifications for which designers can start making a concept design.
- Important to properly discuss requirement specifications with relevant stakeholders before creating a concept design.

**Detailed Design**
- Each designer works on design for part of the system, and specifies how it will be constructed and its different functionality, in addition to any required system or software (UML).

V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing.

## Testing Categories

### Static Testing

Software is tested without code execution.

Review performed to eliminate errors or ambiguities in requirements or design. Code review analysis to find structural defects, such as a variable with an undefined value.

### Dynamic Testing

Software is testing after code execution - checks for functional behaviour, and non-functional requirements, against predefined requirements.

### Black-box Testing

A type of dynamic testing where the internal structure is not known to the tester; they are only concerned with the systems functionality.

### White-box Testing

A type of testing where the internal structure is known to the tester. Explicit paths can be tested; code coverage.

### Gray-box Testing

A combination of white-box and black-box testing.

Internals relevant to the testing are known.

## Code Coverage

A measurement of how many lines of code are executed while automated tests are run - the degree to which the code is executed during testing.

Use 1 or more criteria to determine how your code was tested during execution of the test suite. Common metrics:
- Function Coverage: how many defined functions have been called?
- Statement Coverage: how many statements in the program have been executed?
- Decision Coverage: how many decision edges have been executed?
- Condition (Predicate) Coverage: how many Boolean expressions have been tested for a True and a False value?

```java
public int exampleMethod(int a, int b) {
    int c = 1;
    if ((a >= 0) && (b > 0)) {
        c = a * b;
    }

    return c;
}
```

Metrics
- Function - `exampleMethod` called
- Statement - `exampleMethod(0, 0)` called
- Decision - `exampleMethod(0, 1)` and `exampleMethod(0, 0)`
- Predicate - `exampleMethod(0, 1)`, `exampleMethod(0, 0)` and `exampleMethod(-1, 0)`

## Edge and Corner Cases

Edge cases 
- 1 variable takes maximum or mimimum possible value, zero or non-zero values, positive or negative values.

Corner case
- many variables are at their extremes

Most test cases are focused on the typical system uses, and so often miss situations where the extremes occur.

## Limits of Testing

It's not possible to test every single aspect of even a moderately simple system.
- Too many possible inputs.
- Too many possible paths through the system.

Testing:
- *Cannot* assert that software functions correctly under all conditions.
- *Can* assert that it functions incorrectly under specific conditions.
